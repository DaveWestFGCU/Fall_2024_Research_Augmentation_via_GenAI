{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "c02fd33bce25b9c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:35.129029Z",
     "start_time": "2024-05-29T15:54:35.124523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = 'go_emotions'    # Name of HF dataset to load\n",
    "dataset_subset = 'raw'          # Name of HF subset\n",
    "\n",
    "synthetic_dataset_name = 'merged_synthetic_dataset.parquet'\n",
    "synthetic_dataset_dir = './synthetic_dataset/'\n",
    "\n",
    "batch_size = 10     # Number of synthetic records to generate between saves"
   ],
   "id": "9c83b88d8a35b91c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Common Imports",
   "id": "98fc3f66240c89e7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:38.714999Z",
     "start_time": "2024-05-29T15:54:35.131035Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from IPython.display import display\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import string"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Dataset from HuggingFace",
   "id": "52ef7d1d54d8d219"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "aae5cdbedebedc99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:43.035521Z",
     "start_time": "2024-05-29T15:54:38.716004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orig_dataset = load_dataset(dataset_name, dataset_subset)\n",
    "\n",
    "orig_dataset"
   ],
   "id": "8e01eae439564662",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n",
       "        num_rows: 211225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:43.273381Z",
     "start_time": "2024-05-29T15:54:43.036525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orig_dataset = orig_dataset['train'].to_pandas()\n",
    "\n",
    "# Remove unnecessary columns.\n",
    "# All records have example_very_unclear = False\n",
    "orig_dataset = orig_dataset.drop(['id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear'], axis=1)\n",
    "\n",
    "orig_dataset"
   ],
   "id": "dc798d4ea084bef8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text  admiration  \\\n",
       "0                                         That game hurt.           0   \n",
       "1        >sexuality shouldn’t be a grouping category I...           0   \n",
       "2          You do right, if you don't care then fuck 'em!           0   \n",
       "3                                      Man I love reddit.           0   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...           0   \n",
       "...                                                   ...         ...   \n",
       "211220                             Everyone likes [NAME].           0   \n",
       "211221  Well when you’ve imported about a gazillion of...           0   \n",
       "211222                                 That looks amazing           1   \n",
       "211223  The FDA has plenty to criticize. But like here...           0   \n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...           0   \n",
       "\n",
       "        amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
       "0               0      0          0         0       0          0          0   \n",
       "1               0      0          0         0       0          0          0   \n",
       "2               0      0          0         0       0          0          0   \n",
       "3               0      0          0         0       0          0          0   \n",
       "4               0      0          0         0       0          0          0   \n",
       "...           ...    ...        ...       ...     ...        ...        ...   \n",
       "211220          0      0          0         0       0          0          0   \n",
       "211221          0      0          0         0       1          0          0   \n",
       "211222          0      0          0         0       0          0          0   \n",
       "211223          0      1          0         0       0          0          0   \n",
       "211224          0      0          0         0       0          0          0   \n",
       "\n",
       "        desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
       "0            0  ...     0            0         0      0            0       0   \n",
       "1            0  ...     0            0         0      0            0       0   \n",
       "2            0  ...     0            0         0      0            0       0   \n",
       "3            0  ...     1            0         0      0            0       0   \n",
       "4            0  ...     0            0         0      0            0       0   \n",
       "...        ...  ...   ...          ...       ...    ...          ...     ...   \n",
       "211220       0  ...     1            0         0      0            0       0   \n",
       "211221       0  ...     0            0         0      0            0       0   \n",
       "211222       0  ...     0            0         0      0            0       0   \n",
       "211223       0  ...     0            0         0      0            0       0   \n",
       "211224       0  ...     0            0         0      0            0       0   \n",
       "\n",
       "        remorse  sadness  surprise  neutral  \n",
       "0             0        1         0        0  \n",
       "1             0        0         0        0  \n",
       "2             0        0         0        1  \n",
       "3             0        0         0        0  \n",
       "4             0        0         0        1  \n",
       "...         ...      ...       ...      ...  \n",
       "211220        0        0         0        0  \n",
       "211221        0        0         0        0  \n",
       "211222        0        0         0        0  \n",
       "211223        0        0         0        0  \n",
       "211224        0        0         0        0  \n",
       "\n",
       "[211225 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211225 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:43.279203Z",
     "start_time": "2024-05-29T15:54:43.274387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_columns = orig_dataset.columns.tolist()\n",
    "\n",
    "label_encoding = {}\n",
    "for i, label in enumerate(label_columns[1:]):\n",
    "    label_encoding[label] = i\n",
    "    print(f\"'{label}': {i}\")\n",
    "\n",
    "inverse_encoding = {}\n",
    "for key, value in label_encoding.items():\n",
    "    inverse_encoding[value] = key"
   ],
   "id": "7adc05c2636e0ffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'admiration': 0\n",
      "'amusement': 1\n",
      "'anger': 2\n",
      "'annoyance': 3\n",
      "'approval': 4\n",
      "'caring': 5\n",
      "'confusion': 6\n",
      "'curiosity': 7\n",
      "'desire': 8\n",
      "'disappointment': 9\n",
      "'disapproval': 10\n",
      "'disgust': 11\n",
      "'embarrassment': 12\n",
      "'excitement': 13\n",
      "'fear': 14\n",
      "'gratitude': 15\n",
      "'grief': 16\n",
      "'joy': 17\n",
      "'love': 18\n",
      "'nervousness': 19\n",
      "'optimism': 20\n",
      "'pride': 21\n",
      "'realization': 22\n",
      "'relief': 23\n",
      "'remorse': 24\n",
      "'sadness': 25\n",
      "'surprise': 26\n",
      "'neutral': 27\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.064362Z",
     "start_time": "2024-05-29T15:54:43.281230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggregate labels in a list column\n",
    "orig_dataset.insert(1,'labels','')\n",
    "orig_dataset['labels'] = orig_dataset[label_columns[1:]].values.tolist()\n",
    "orig_dataset['labels'] = orig_dataset['labels'].apply(lambda t: [i for i, x in enumerate(t) if x])\n",
    "\n",
    "# Remove unlabeled records\n",
    "orig_dataset = orig_dataset[orig_dataset['labels'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "orig_dataset"
   ],
   "id": "78fd6b08fe61fac0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text labels  admiration  \\\n",
       "0                                         That game hurt.   [25]           0   \n",
       "2          You do right, if you don't care then fuck 'em!   [27]           0   \n",
       "3                                      Man I love reddit.   [18]           0   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...   [27]           0   \n",
       "5       Right? Considering it’s such an important docu...   [15]           0   \n",
       "...                                                   ...    ...         ...   \n",
       "211219  Well, I'm glad you're out of all that now. How...   [17]           0   \n",
       "211220                             Everyone likes [NAME].   [18]           0   \n",
       "211221  Well when you’ve imported about a gazillion of...    [5]           0   \n",
       "211222                                 That looks amazing    [0]           1   \n",
       "211223  The FDA has plenty to criticize. But like here...    [2]           0   \n",
       "\n",
       "        amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
       "0               0      0          0         0       0          0          0   \n",
       "2               0      0          0         0       0          0          0   \n",
       "3               0      0          0         0       0          0          0   \n",
       "4               0      0          0         0       0          0          0   \n",
       "5               0      0          0         0       0          0          0   \n",
       "...           ...    ...        ...       ...     ...        ...        ...   \n",
       "211219          0      0          0         0       0          0          0   \n",
       "211220          0      0          0         0       0          0          0   \n",
       "211221          0      0          0         0       1          0          0   \n",
       "211222          0      0          0         0       0          0          0   \n",
       "211223          0      1          0         0       0          0          0   \n",
       "\n",
       "        ...  love  nervousness  optimism  pride  realization  relief  remorse  \\\n",
       "0       ...     0            0         0      0            0       0        0   \n",
       "2       ...     0            0         0      0            0       0        0   \n",
       "3       ...     1            0         0      0            0       0        0   \n",
       "4       ...     0            0         0      0            0       0        0   \n",
       "5       ...     0            0         0      0            0       0        0   \n",
       "...     ...   ...          ...       ...    ...          ...     ...      ...   \n",
       "211219  ...     0            0         0      0            0       0        0   \n",
       "211220  ...     1            0         0      0            0       0        0   \n",
       "211221  ...     0            0         0      0            0       0        0   \n",
       "211222  ...     0            0         0      0            0       0        0   \n",
       "211223  ...     0            0         0      0            0       0        0   \n",
       "\n",
       "        sadness  surprise  neutral  \n",
       "0             1         0        0  \n",
       "2             0         0        1  \n",
       "3             0         0        0  \n",
       "4             0         0        1  \n",
       "5             0         0        0  \n",
       "...         ...       ...      ...  \n",
       "211219        0         0        0  \n",
       "211220        0         0        0  \n",
       "211221        0         0        0  \n",
       "211222        0         0        0  \n",
       "211223        0         0        0  \n",
       "\n",
       "[207814 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>[25]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>[27]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>[18]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important docu...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How...</td>\n",
       "      <td>[17]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>[18]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207814 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generating Synthetic Data\n",
    "## Functions"
   ],
   "id": "5314b43e098f2dea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.069367Z",
     "start_time": "2024-05-29T15:54:44.065367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_random_record(dataset, enc_target_label):\n",
    "    # Temp remove target labeled records and get a random record from remaining dataset\n",
    "    sample = dataset[~dataset['labels'].apply(lambda x: enc_target_label in x)].sample()\n",
    "    # If a neutral sample is randomly selected, select again until it's something not-neutral\n",
    "    while 27 in sample['labels'].tolist()[0]:\n",
    "       sample = dataset[~dataset['labels'].apply(lambda x: enc_target_label in x)].sample()\n",
    "    \n",
    "    return sample"
   ],
   "id": "53dfe8424563096b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.090047Z",
     "start_time": "2024-05-29T15:54:44.070375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_prompt(sample, enc_target_label):\n",
    "    sample_text = sample['text'].values[0]\n",
    "    print(sample_text)\n",
    "    # Translate list of encoded labels to prompt\n",
    "    match len(sample['labels'].values[0]):\n",
    "        case 1:\n",
    "            sample_label = inverse_encoding[sample['labels'].values[0][0]]\n",
    "\n",
    "        case 2:\n",
    "            sample_label = (inverse_encoding[sample['labels'].values[0][0]] + \" and \" \n",
    "                            + inverse_encoding[sample['labels'].values[0][1]])\n",
    "            \n",
    "        case _:\n",
    "            sample_label = inverse_encoding[sample['labels'].values[0][0]]\n",
    "            for label in sample['labels'].values[0][1:]:\n",
    "                if label != sample['labels'].values[0][-1]:\n",
    "                    sample_label += ', ' + inverse_encoding[label]\n",
    "                else:\n",
    "                    sample_label += ', and ' + inverse_encoding[label]       \n",
    "    \n",
    "    print(sample_label)\n",
    "    \n",
    "    if len(sample['labels'].values[0]) == 1:\n",
    "        sample_label = ' ' + sample_label\n",
    "    else:\n",
    "        sample_label = 's ' + sample_label\n",
    "        \n",
    "    old_query = f\"The comment \\\"{sample_text}\\\" portrays the emotion{sample_label}. Based on the topic of this comment, generate a new comment that would portrays a clear example of {inverse_encoding[enc_target_label]}\"\n",
    "    \n",
    "    new_query = f\"Using the comment \\\"{sample_text}\\\" which portrays the emotion{sample_label}, generate a similar comment that instead portrays {inverse_encoding[enc_target_label]}\"\n",
    "    \n",
    "    return new_query"
   ],
   "id": "4b3f85c8f81a59a9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.095618Z",
     "start_time": "2024-05-29T15:54:44.091051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removes all line breaks, spaces from start/end, and punctuation from start\n",
    "# If labels=True, removes all punctuation and lower cases the string\n",
    "# If labels=False, removes trailing quotes if inappropriate\n",
    "def clean_response(text, labels=False):\n",
    "    \n",
    "    text = text.replace('\\n', ' ')\n",
    "    try:\n",
    "        text[0]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    else:\n",
    "        while text[0] == ' ' or text[0] in \"!#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\":\n",
    "            text = text[1:]\n",
    "    \n",
    "        while text[-1] == ' ':\n",
    "            text = text[:-1]\n",
    "    \n",
    "    if labels:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    \n",
    "    if not labels:\n",
    "        if text.count('\"') == 0:\n",
    "            print(\"NO QUOTE RESPONSE\")\n",
    "        elif text.count('\"') % 2 == 0:\n",
    "            text = text[text.find('\"')+1:text.rfind('\"')]\n",
    "        else:\n",
    "            text = text[text.find('\"')+1:]\n",
    "\n",
    "    return text"
   ],
   "id": "57833ce77cb7fdcf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.100684Z",
     "start_time": "2024-05-29T15:54:44.096623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_label_prompts(enc_target_label, response_text):\n",
    "    target_query = f\"Does the comment \\\"{response_text}\\\" portray the emotion {inverse_encoding[enc_target_label]}? Limit your answer to yes or no.\"\n",
    "    \n",
    "    valid_emotions = ', '.join(label_columns[2:])\n",
    "    valid_emotions = \"[\" + valid_emotions + \"]\"\n",
    "    \n",
    "    other_query = f\"Classify the comment \\\"{response_text}\\\" by one or more emotions ONLY from the following list: {valid_emotions}\"\n",
    "    \n",
    "    return target_query, other_query"
   ],
   "id": "10ba506a0444f9c4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.106350Z",
     "start_time": "2024-05-29T15:54:44.101689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def target_consensus(query_text):\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\", \n",
    "        prompt=query_text,\n",
    "        temperature=1,\n",
    "        n=5,\n",
    "        logit_bias={\"1734\": -100}\n",
    "    )\n",
    "    \n",
    "    responses = [clean_response(choice.text, labels=True) for choice in response.choices]\n",
    "    \n",
    "    # Cutoff for a consensus is 4/5 yes votes\n",
    "    if sum('yes' in text for text in responses) >= 4:\n",
    "        return True\n",
    "    elif sum('no' in text for text in responses) >= 2:\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Unexpected responses: \" + responses)\n",
    "    \n",
    "    return False"
   ],
   "id": "ea7bff4ce0ecc11c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:54:44.112546Z",
     "start_time": "2024-05-29T15:54:44.107358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prompts LLM for emotion labels from a text. Returns a list of emotions 4 of 5 prompts included\n",
    "def get_labels(query_text):\n",
    "    \n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\", \n",
    "        prompt=query_text,\n",
    "        temperature=1,\n",
    "        n=5,\n",
    "        logit_bias={\"1734\": -100}\n",
    "    )\n",
    "    \n",
    "    responses = [clean_response(choice.text, labels=True) for choice in response.choices]\n",
    "    \n",
    "    response_labels = [text.split(\" \") for text in responses]\n",
    "    response_labels = [label.lower() for labels in response_labels for label in labels]   # flatten the list\n",
    "    \n",
    "    label_list = []\n",
    "    while response_labels:\n",
    "        label = response_labels[0]\n",
    "        \n",
    "        if label in label_columns[2:]:  # Make sure the word is a valid label                \n",
    "            if response_labels.count(label) >= 4:   # 4/5 responses included the label\n",
    "                label_list.append(label)\n",
    "        \n",
    "        # Remove duplicates of current label\n",
    "        while label in response_labels:\n",
    "            response_labels.remove(label)\n",
    "    \n",
    "    return label_list"
   ],
   "id": "7d03b5f2835686de",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization",
   "id": "eae44406c6af982b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:58:51.680998Z",
     "start_time": "2024-05-29T15:58:51.303566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "# Build a list of how imbalanced each class is\n",
    "label_values = pd.Series([x for item in orig_dataset.labels for x in item]).value_counts()\n",
    "\n",
    "# Avoid conforming to 'neutral' if its the major class\n",
    "largest_label_counts = label_values.nlargest(2)\n",
    "if largest_label_counts.index[0] == label_encoding['neutral']:\n",
    "    label_imbalance_values = largest_label_counts.iloc[1] - label_values\n",
    "else:\n",
    "    label_imbalance_values = largest_label_counts.iloc[0] - label_values\n",
    "\n",
    "label_imbalance_values.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "label_imbalance_values"
   ],
   "id": "caceb6deec87b2fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       489\n",
       "1      8375\n",
       "2      9536\n",
       "3      4002\n",
       "4         0\n",
       "5     11621\n",
       "6     10261\n",
       "7      7928\n",
       "8     13803\n",
       "9      9151\n",
       "10     6196\n",
       "11    12319\n",
       "12    15144\n",
       "13    11991\n",
       "14    14423\n",
       "15     5995\n",
       "16    16947\n",
       "17     9637\n",
       "18     9429\n",
       "19    15810\n",
       "20     8905\n",
       "21    16318\n",
       "22     8835\n",
       "23    16331\n",
       "24    15095\n",
       "25    10862\n",
       "26    12106\n",
       "27   -37678\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:58:54.150686Z",
     "start_time": "2024-05-29T15:58:54.128001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get or build a synthetic dataset\n",
    "try:\n",
    "    synth_dataset = pd.read_parquet(path=synthetic_dataset_dir+synthetic_dataset_name)\n",
    "except FileNotFoundError:\n",
    "    synth_dataset = pd.DataFrame(columns = ['text', 'labels', 'source index', 'source labels', 'intended label'])\n",
    "else:\n",
    "    # Remove synthesized dataset label counts from imbalance counts\n",
    "    display(synth_dataset)\n",
    "    synth_label_values = pd.Series(\n",
    "        index=[key for key, value in label_encoding.items()],\n",
    "        data=pd.Series([x for item in synth_dataset.labels for x in item]).value_counts()\n",
    "    )\n",
    "    # Encode synth series\n",
    "    synth_label_values.rename(index=label_encoding, inplace=True)\n",
    "    \n",
    "    label_imbalance_values = label_imbalance_values - synth_label_values\n",
    "\n",
    "label_imbalance_values"
   ],
   "id": "4cb76a8d9faa37bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text  \\\n",
       "0    Deducing logical conclusions may not be your f...   \n",
       "1    I wonder what he's listening to... I miss the ...   \n",
       "2    I miss you so much, [NAME]. It's hard to imagi...   \n",
       "3    My heart aches for Goobi. I miss them so much,...   \n",
       "4    Despite all the effort, it's still not enough....   \n",
       "..                                                 ...   \n",
       "495  Wait, so they were diagnosed at the airport bu...   \n",
       "496  Not gonna lie, not feeling any spark of joy or...   \n",
       "497  I can't believe I didn't see this before, it's...   \n",
       "498  > [Citation needed] Are you sure no woman will...   \n",
       "499  What on earth was [NAME] thinking when making ...   \n",
       "\n",
       "                               labels  source index  \\\n",
       "0                         [confusion]         45738   \n",
       "1                             [grief]          2140   \n",
       "2              [grief, love, sadness]         38580   \n",
       "3              [grief, sadness, love]         59923   \n",
       "4    [grief, disappointment, sadness]        204328   \n",
       "..                                ...           ...   \n",
       "495                       [confusion]        168266   \n",
       "496                  [disappointment]         54109   \n",
       "497           [realization, surprise]         93092   \n",
       "498                       [curiosity]        197772   \n",
       "499      [disapproval, embarrassment]        111447   \n",
       "\n",
       "                     source labels intended label  \n",
       "0                    [disapproval]          grief  \n",
       "1              [curiosity, desire]          grief  \n",
       "2                   [caring, love]          grief  \n",
       "3                           [love]          grief  \n",
       "4                 [disappointment]          grief  \n",
       "..                             ...            ...  \n",
       "495                  [realization]      confusion  \n",
       "496  [disappointment, disapproval]      amusement  \n",
       "497                   [admiration]    realization  \n",
       "498          [curiosity, optimism]           fear  \n",
       "499                    [curiosity]  embarrassment  \n",
       "\n",
       "[804 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>source index</th>\n",
       "      <th>source labels</th>\n",
       "      <th>intended label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deducing logical conclusions may not be your f...</td>\n",
       "      <td>[confusion]</td>\n",
       "      <td>45738</td>\n",
       "      <td>[disapproval]</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I wonder what he's listening to... I miss the ...</td>\n",
       "      <td>[grief]</td>\n",
       "      <td>2140</td>\n",
       "      <td>[curiosity, desire]</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I miss you so much, [NAME]. It's hard to imagi...</td>\n",
       "      <td>[grief, love, sadness]</td>\n",
       "      <td>38580</td>\n",
       "      <td>[caring, love]</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My heart aches for Goobi. I miss them so much,...</td>\n",
       "      <td>[grief, sadness, love]</td>\n",
       "      <td>59923</td>\n",
       "      <td>[love]</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite all the effort, it's still not enough....</td>\n",
       "      <td>[grief, disappointment, sadness]</td>\n",
       "      <td>204328</td>\n",
       "      <td>[disappointment]</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Wait, so they were diagnosed at the airport bu...</td>\n",
       "      <td>[confusion]</td>\n",
       "      <td>168266</td>\n",
       "      <td>[realization]</td>\n",
       "      <td>confusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Not gonna lie, not feeling any spark of joy or...</td>\n",
       "      <td>[disappointment]</td>\n",
       "      <td>54109</td>\n",
       "      <td>[disappointment, disapproval]</td>\n",
       "      <td>amusement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>I can't believe I didn't see this before, it's...</td>\n",
       "      <td>[realization, surprise]</td>\n",
       "      <td>93092</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>realization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>&gt; [Citation needed] Are you sure no woman will...</td>\n",
       "      <td>[curiosity]</td>\n",
       "      <td>197772</td>\n",
       "      <td>[curiosity, optimism]</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>What on earth was [NAME] thinking when making ...</td>\n",
       "      <td>[disapproval, embarrassment]</td>\n",
       "      <td>111447</td>\n",
       "      <td>[curiosity]</td>\n",
       "      <td>embarrassment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       463\n",
       "1      8347\n",
       "2      9496\n",
       "3      3954\n",
       "4       -86\n",
       "5     11570\n",
       "6     10223\n",
       "7      7881\n",
       "8     13787\n",
       "9      9002\n",
       "10     6112\n",
       "11    12295\n",
       "12    15128\n",
       "13    11905\n",
       "14    14405\n",
       "15     5920\n",
       "16    16743\n",
       "17     9613\n",
       "18     9394\n",
       "19    15794\n",
       "20     8884\n",
       "21    16295\n",
       "22     8816\n",
       "23    16302\n",
       "24    15069\n",
       "25    10634\n",
       "26    12085\n",
       "27   -37689\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Main Loop",
   "id": "fee6365cbffee43b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_num = 1\n",
    "\n",
    "enc_target_label = label_imbalance_values.idxmax()\n",
    "target_label = inverse_encoding[enc_target_label]\n",
    "\n",
    "while label_imbalance_values.max() > 0:\n",
    "    print(f\"Target: {target_label} : {enc_target_label} : {label_imbalance_values[enc_target_label]}\")\n",
    "    \n",
    "    sample = get_random_record(orig_dataset, enc_target_label)\n",
    "    text_query = generate_text_prompt(sample, enc_target_label)\n",
    "    \n",
    "    # OpenAI InstructGPT\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\", \n",
    "        prompt=text_query, \n",
    "        max_tokens=50, \n",
    "        logit_bias={\"1734\": -100} # Remove line breaks\n",
    "    )\n",
    "    \n",
    "    response_text = clean_response(response.choices[0].text)    # InstructGPT response starts with \\n\\n\n",
    "    \n",
    "    assert response_text, f\"Entry wiped by clean_response(): {response.choices[0].text}\" \n",
    "    print(\"Synthetic Record Text: \" + response_text)\n",
    "    \n",
    "    target_query, other_labels_query = generate_label_prompts(enc_target_label, response_text)\n",
    "    \n",
    "    # Does the generated text match the intended label?\n",
    "    if target_consensus(target_query):\n",
    "        consensus_labels = [inverse_encoding[enc_target_label]]\n",
    "    else:\n",
    "        consensus_labels = []\n",
    "    \n",
    "    synth_record_labels = get_labels(other_labels_query)\n",
    "    \n",
    "    if synth_record_labels:\n",
    "        if consensus_labels and target_label not in synth_record_labels:\n",
    "            consensus_labels += synth_record_labels\n",
    "        else:\n",
    "            consensus_labels = synth_record_labels\n",
    "    \n",
    "    print(f\"Synthetic labels: {consensus_labels}\")\n",
    "    \n",
    "    # Only save if a label is found\n",
    "    if consensus_labels:\n",
    "        source_labels = orig_dataset.loc[sample.index.values[0], 'labels']\n",
    "        source_labels = list(map(inverse_encoding.get, source_labels))\n",
    "        next_row = len(synth_dataset)\n",
    "        synth_dataset.loc[next_row] = { 'text': response_text, \n",
    "                                        'labels': consensus_labels, \n",
    "                                        'source index': sample.index.values[0], \n",
    "                                        'source labels': source_labels, \n",
    "                                        'intended label': inverse_encoding[enc_target_label]  }\n",
    "        \n",
    "        if batch_num % batch_size == 0:\n",
    "            print(f\"\\nSaving data. {len(synth_dataset)} records.\")\n",
    "            try:\n",
    "                synth_dataset.to_parquet(path=synthetic_dataset_dir+synthetic_dataset_name)\n",
    "            except OSError:\n",
    "                os.makedirs(synthetic_dataset_dir)\n",
    "                synth_dataset.to_parquet(path=synthetic_dataset_dir+synthetic_dataset_name)\n",
    "\n",
    "\n",
    "    # Update label values\n",
    "    for label in consensus_labels:\n",
    "        label_imbalance_values[label_encoding[label]] -= 1\n",
    "        \n",
    "        # If the synthetic data label doesn't include the target label, the target is still the highest imbalance\n",
    "        if label == target_label:\n",
    "            enc_target_label = label_imbalance_values.idxmax()\n",
    "            target_label = inverse_encoding[enc_target_label]\n",
    "    \n",
    "    batch_num += 1\n",
    "    print()\n",
    "\n",
    "try:\n",
    "    synth_dataset.to_parquet(path=synthetic_dataset_dir+synthetic_dataset_name)\n",
    "except OSError:\n",
    "    os.makedirs(synthetic_dataset_dir)\n",
    "    synth_dataset.to_parquet(path=synthetic_dataset_dir+synthetic_dataset_name)\n",
    "\n",
    "print(f\"\\nSaving data. {len(synth_dataset)} records.\")"
   ],
   "id": "1b4f457b9ab179cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "synth_dataset",
   "id": "668c4efe79d3e67e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
